{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import requests as r\n",
    "import math\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./0*.csv\")\n",
    "output_folder = \"./json-source-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./02_resources.csv',\n",
       " './03_events.csv',\n",
       " './05_technologies.csv',\n",
       " './04_policies-modified.csv',\n",
       " './06_tags.csv',\n",
       " './09.country_groups.csv',\n",
       " './04_policies.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET ALL ORGANISTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "orglist = []\n",
    "for file in files:\n",
    "    data = pd.read_csv(file)\n",
    "    try:\n",
    "        orgs = list(data[data['organisation'] == data['organisation']]['organisation'])\n",
    "        for org in orgs:\n",
    "            org = org.replace('\"','').replace(',',';').split(';')\n",
    "            for og in org:\n",
    "                og = og.strip()\n",
    "                if og != '':\n",
    "                    orglist.append(og.strip())\n",
    "    except:\n",
    "        pass\n",
    "orglist = list(np.unique(orglist))\n",
    "orglist = [{\"name\":org} for org in orglist]\n",
    "with open(output_folder + '/organisations.json', 'w') as file:\n",
    "    file.write(json.dumps(orglist, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIST ALL MEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./06_tags.csv\n",
      "./09.country_groups.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dedenbangkit/miniconda3/lib/python3.8/site-packages/pandas/core/strings.py:2001: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "  return func(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#get unique reqgional coverage\n",
    "mea = []\n",
    "for file in files:\n",
    "    df = pd.read_csv(file)\n",
    "    try:\n",
    "        df = df[df['geo_coverage'] == df['geo_coverage']]\n",
    "        df['geo_coverage_type'] = df['geo_coverage'].apply(lambda x: x.split(':')[0].lower() if ':' in x else np.nan)\n",
    "        df['geo_coverage'] = df['geo_coverage'].apply(lambda x: x.split(':')[1] if ':' in x else x)\n",
    "        df = df[df['geo_coverage_type'] == df['geo_coverage_type']]\n",
    "        df = df[['geo_coverage_type','geo_coverage']].to_dict('records')\n",
    "        for d in df:\n",
    "            if 'specific areas' in d['geo_coverage_type'] or d['geo_coverage_type'] == 'regional':\n",
    "                if ';' in d['geo_coverage']:\n",
    "                    dd = d['geo_coverage'].split(';')\n",
    "                    for gc in dd:\n",
    "                        mea.append({'coverage':gc.strip(),'type': d['geo_coverage_type']})\n",
    "                else:\n",
    "                    mea.append(mea.append({'coverage':d['geo_coverage'].strip(),'type':d['geo_coverage_type']}))\n",
    "    except:\n",
    "        print(file)\n",
    "mea = [i for i in mea if i]\n",
    "pd.DataFrame(mea).drop_duplicates(subset=['coverage'])\n",
    "new = pd.read_csv('./country_group.csv')\n",
    "new['source'] = 'new'\n",
    "old = pd.DataFrame(r.get(\"http://unep.localhost/api/public/groups\").json())\n",
    "old['source_api'] = 'unep.tc'\n",
    "old = old[['name','source_api']]\n",
    "new['duplicates'] = new['name'].apply(lambda x: old.loc[old['name'].str.contains(x)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET ALL TAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tags = pd.read_csv('./06_tags.csv')\n",
    "tags['category'] = tags['category'].apply(lambda x: x.split('_')[1])\n",
    "tags = tags[['category','tag']]\n",
    "tags = tags.groupby('category')['tag'].apply(lambda g: g.values.tolist()).to_dict()\n",
    "with open(output_folder + '/tags.json', 'w') as file:\n",
    "    file.write(json.dumps(tags, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET COUNTRY GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = pd.read_csv('./09.country_groups.csv')\n",
    "groups['country'] = groups['country'].apply(lambda x: x.strip())\n",
    "countryGroup = groups.groupby('group')['country'].apply(lambda g: g.values.tolist()).to_dict()\n",
    "with open(output_folder + '/country_group.json', 'w') as file:\n",
    "    file.write(json.dumps(countryGroup, indent=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET ALL RESOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(x):\n",
    "    if \"€\" in x or \"EUR\" in x:\n",
    "        return \"EUR\"\n",
    "    if \"$\" in x or \"USD\" in x:\n",
    "        return \"USD\"\n",
    "    if \"NOK\" in x:\n",
    "        return \"NOK\"\n",
    "    if \"CAD\" in x:\n",
    "        return \"CAD\"\n",
    "    if \"GBP\" in x or \"£\":\n",
    "        return \"GBP\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value_currency(x):\n",
    "    cur = [int(s) for s in x.split() if s.isdigit()]\n",
    "    if len(cur) == 1:\n",
    "        if \"milli\" in x:\n",
    "            return cur[0] * 1000000\n",
    "        if \"billi\" in x:\n",
    "            return cur[0] * 1000000000\n",
    "        return cur[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_theme(theme):\n",
    "    srcs = pd.read_csv(theme)\n",
    "    taglist = pd.read_csv('./06_tags.csv')\n",
    "    taglist = [t.strip() for t in list(taglist['tag'])]\n",
    "    coverage_type = ['global',\n",
    "                     'regional',\n",
    "                     'national',\n",
    "                     'transnational',\n",
    "                     'sub-national',\n",
    "                     'global with elements in specific areas']\n",
    "    srcs = srcs.to_dict('records')\n",
    "    resources = []\n",
    "    false_tags = []\n",
    "    for src in srcs:\n",
    "        res = {}\n",
    "        for s in src:\n",
    "            res.update({s:src[s]})\n",
    "            if type(src[s]) == float:\n",
    "                if math.isnan(src[s]):\n",
    "                    res.update({s: None})\n",
    "            if s in [\"publish_year\",\"valid_from\",\"valid_to\"]:\n",
    "                if res[s] is not None:\n",
    "                    res.update({s: int(res[s])})\n",
    "            if s == \"url\":\n",
    "                if res[s] is not None:\n",
    "                    res.update({\"url\": [v.strip() for v in res[s].splitlines(True)]})\n",
    "            if s == \"languages\":\n",
    "                languages = []\n",
    "                if res[s] is not None:\n",
    "                    lang = []\n",
    "                    if \":\" in res[s]:\n",
    "                        lang = res[s].replace(\"http://\",\"\").replace(\"https://\",\"\").split(';')\n",
    "                    if len(lang) > 0:\n",
    "                        for ln in lang:\n",
    "                            ln = ln.split(\":\")\n",
    "                            if len(ln) > 1:\n",
    "                                languages.append({\"language\":ln[0].strip(),\"url\":\"https://{}\".format(ln[1].strip())})\n",
    "                if len(languages) > 0:\n",
    "                    res.update({\"resource_language_url\": languages})\n",
    "                else:\n",
    "                    res.update({\"resource_language_url\": None})\n",
    "                #del res[s]\n",
    "            if type(res[s]) == str:\n",
    "                v = res[s].replace('\\n','').replace('\"','').replace('‘','').replace('’','').replace('\\xa0',' ')\n",
    "                v = v.strip()\n",
    "                res.update({s: v})\n",
    "            ## Should we do data cleaning for value?\n",
    "            if s == \"value\":\n",
    "                if res[s] is not None:\n",
    "                    res.update({\"value_currency\": get_currency(res[s])})\n",
    "                    res.update({s: get_value_currency(res[s])})\n",
    "                else:\n",
    "                    res.update({\"value_currency\": None})\n",
    "            if s in [\"tags\",\"organisation\"]:\n",
    "                if type(res[s]) == str:\n",
    "                    vl = []\n",
    "                    if res[s] is not None:\n",
    "                        sep = [';' if ';' in src[s] else ':']\n",
    "                        vl = res[s].split(sep[0])\n",
    "                        vl = [k.replace('\"','').strip() for k in vl]\n",
    "                        if s == \"tags\":\n",
    "                            nv = []\n",
    "                            for tg in taglist:\n",
    "                                for v in vl:\n",
    "                                    if v == tg:\n",
    "                                        nv.append(v)\n",
    "                                    if v not in taglist:\n",
    "                                        false_tags.append(v)\n",
    "                            #if len(vl) != len(nv):\n",
    "                            #    res.update({\"error_tags\":True})\n",
    "                            #else:\n",
    "                            #    res.update({\"error_tags\":False})\n",
    "                            vl = nv\n",
    "                    if len(vl) == 0:\n",
    "                        vl = None\n",
    "                    res.update({s: vl})\n",
    "            if s == \"geo_coverage\":\n",
    "                if res[s] is not None:\n",
    "                    gt = res[s].split(\":\")\n",
    "                    ct = gt[0].lower().strip()\n",
    "                    if ct in coverage_type:\n",
    "                        res.update({'geo_coverage_type': ct})\n",
    "                    else:\n",
    "                        res.update({'geo_coverage_type': None})\n",
    "                    if len(gt) > 1:\n",
    "                        gc = gt[1].split(';')\n",
    "                        gc = [g.replace('.','').strip().title() for g in gc]\n",
    "                        res.update({s: gc})\n",
    "                    else:\n",
    "                        res.update({s: None})\n",
    "            if s == \"attachments\":\n",
    "                if res[s] is not None:\n",
    "                    res.update({s: res[s].split(' ')})\n",
    "                else:\n",
    "                    res.update({s: []})\n",
    "            if s == \"country\":\n",
    "                if res[s] is not None:\n",
    "                    if \",\" in res[s]:\n",
    "                        country = res[s].split(',')\n",
    "                    elif \";\" in res[s]:\n",
    "                        country = res[s].split(';')\n",
    "                    else:\n",
    "                        country = [res[s]]\n",
    "                    res.update({\"country\": country[0]})\n",
    "                else:\n",
    "                    res.update({\"country\": None})\n",
    "        resources.append(res)\n",
    "    results = pd.DataFrame(resources).to_dict('records')\n",
    "    #df = df.fillna(dict(publish_year=999)).replace(dict(publish_year={999: None}))\n",
    "    for res in results:\n",
    "        for s in res:\n",
    "            if type(res[s]) == float:\n",
    "                if math.isnan(res[s]):\n",
    "                    res.update({s: None})\n",
    "                else:\n",
    "                    res.update({s: int(res[s])})\n",
    "    resources = pd.DataFrame(results)\n",
    "    with open('{}/{}.json'.format(output_folder, theme.replace('.csv','')), 'w') as file:\n",
    "        file.write(json.dumps(results, indent=1))\n",
    "    print(\"theme {}.json generated\".format(theme.replace('.csv','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theme 05_technologies.json generated\n",
      "theme 04_policies.json generated\n",
      "theme 02_resources.json generated\n"
     ]
    }
   ],
   "source": [
    "generate_theme(\"05_technologies.csv\")\n",
    "generate_theme(\"04_policies.csv\")\n",
    "generate_theme(\"02_resources.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES\n",
    "- Do we need to analyze value and it's currency?\n",
    "- No Country Table\n",
    "- Country also has **global with elements in specific areas**\n",
    "- Some of the country has different separator\n",
    "- Some of the geo_coverage has different separator\n",
    "- Some of the tags has different separator\n",
    "- languages separator is using colon while the url is also using colon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
